

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Quickstart &mdash; SESEMI  documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="A Primer on Hydra" href="hydra.html" />
    <link rel="prev" title="Image Classification with Self-Supervised Regularization" href="index.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> SESEMI
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Quickstart</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#structured-configurations">Structured Configurations</a></li>
<li class="toctree-l2"><a class="reference internal" href="#built-in-configurations">Built-in Configurations</a></li>
<li class="toctree-l2"><a class="reference internal" href="#datasets">Datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="#example">Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="#usage">Usage</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="hydra.html">A Primer on Hydra</a></li>
<li class="toctree-l1"><a class="reference internal" href="sesemi.html">sesemi package</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">SESEMI</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Quickstart</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/quickstart.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="quickstart">
<h1>Quickstart<a class="headerlink" href="#quickstart" title="Permalink to this headline">¶</a></h1>
<p>To install the sesemi package you can run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ pip install sesemi
</pre></div>
</div>
<p>This will download and configure an <em>open_sesemi</em> CLI which you can inspect as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ open_sesemi -h
cli is powered by Hydra.

== Configuration groups ==
Compose your configuration from those groups (group=option)

learner: classifier


== Config ==
Override anything in the config (foo.bar=value)

run:
  seed: null
  num_epochs: null
  num_iterations: null
  gpus: -1
  num_nodes: 1
  accelerator: null
  batch_size_per_gpu: null
  data_root: ./data
  id: default
  dir: ./runs
  mode: FIT
  resume_from_checkpoint: null
  pretrained_checkpoint_path: null
data:
  train: null
  val: null
  test: null
learner:
  _target_: sesemi.Classifier
  hparams:
    num_classes: ???
    model:
      backbone: ???
      supervised_loss:
        callable: ???
        scheduler: null
        reduction: mean
        scale_factor: 1.0
      regularization_loss_heads: null
    optimizer: ???
    lr_scheduler: null
trainer: null


Powered by Hydra (https://hydra.cc)
Use --hydra-help to view Hydra specific help


Powered by Hydra (https://hydra.cc)
Use --hydra-help to view Hydra specific help
</pre></div>
</div>
<p>The CLI is configured using <a class="reference external" href="https://hydra.cc/">Hydra</a>. This is useful for the following reasons:</p>
<ul class="simple">
<li><p>Enables defining YAML configuration files that fully specify the run configuration.</p></li>
<li><p>Cleanly maps configurations to internal and external objects through the use of the <a class="reference external" href="https://hydra.cc/docs/advanced/instantiate_objects/overview">instantiation</a> features.</p></li>
<li><p>Supports composition of configurations through different override mechanisms.</p></li>
<li><p>Makes it easy to define a collection of built-in configuration files accessible by the user.</p></li>
</ul>
<p>Although Hydra is a flexible system for configuration management, it is somewhat complex which is why we have
developed a brief primer on the subject. Please see that page for additional background.</p>
<div class="section" id="structured-configurations">
<h2>Structured Configurations<a class="headerlink" href="#structured-configurations" title="Permalink to this headline">¶</a></h2>
<p>The config shown by the help text above is actually defined using a set of Python data structures. In particular,
data classes with type annotations are used. For example, some of the root configuration data structures are shown below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">SESEMIConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;The full SESEMI configuration.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        run: The run config.</span>
<span class="sd">        data: The data config.</span>
<span class="sd">        learner: The learner config.</span>
<span class="sd">        trainer: Optional additional parameters that can be passed to a PyTorch Lightning Trainer</span>
<span class="sd">            object.</span>

<span class="sd">    References:</span>
<span class="sd">        * https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html#trainer-class-api</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">run</span><span class="p">:</span> <span class="n">RunConfig</span> <span class="o">=</span> <span class="n">RunConfig</span><span class="p">()</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">DataConfig</span> <span class="o">=</span> <span class="n">DataConfig</span><span class="p">()</span>
    <span class="n">learner</span><span class="p">:</span> <span class="n">LearnerConfig</span> <span class="o">=</span> <span class="n">LearnerConfig</span><span class="p">()</span>
    <span class="n">trainer</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span>


<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">RunConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;The run configuration.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        seed: An optional random seed used on initialization.</span>
<span class="sd">        num_epochs: The number of training epochs to train. Cannot be set with `num_iterations`.</span>
<span class="sd">        num_iterations: The number of training iterations to run. Cannot be set with `num_epochs`.</span>
<span class="sd">        gpus: Either an integer specifying the number of GPUs to use, a list of GPU</span>
<span class="sd">            integer IDs, a comma-separated list of GPU IDs, or None to train on the CPU. Setting</span>
<span class="sd">            this to -1 uses all GPUs and setting it to 0 also uses the CPU.</span>
<span class="sd">        num_nodes: The number of nodes to use during training (defaults to 1).</span>
<span class="sd">        accelerator: Supports either &quot;dp&quot; or &quot;ddp&quot; (the default).</span>
<span class="sd">        batch_size_per_gpu: An optional default batch size per GPU to use with all data loaders.</span>
<span class="sd">        data_root: The directory to use as the parent of relative dataset root directories</span>
<span class="sd">            (see `DatasetConfig`).</span>
<span class="sd">        id: The identifier to use for the run.</span>
<span class="sd">        dir: The directory to store run outputs (e.g. logs, configurations, etc.).</span>
<span class="sd">        mode: The run&#39;s mode.</span>
<span class="sd">        resume_from_checkpoint: An optional checkpoint path to restore trainer state.</span>
<span class="sd">        pretrained_checkpoint_path: An optional checkpoint path to load pretrained model weights.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">num_epochs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">num_iterations</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">gpus</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="n">num_nodes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">accelerator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">batch_size_per_gpu</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">data_root</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;./data&quot;</span>
    <span class="nb">id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;default&quot;</span>
    <span class="nb">dir</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;./runs&quot;</span>
    <span class="n">mode</span><span class="p">:</span> <span class="n">RunMode</span> <span class="o">=</span> <span class="n">RunMode</span><span class="o">.</span><span class="n">FIT</span>
    <span class="n">resume_from_checkpoint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">pretrained_checkpoint_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>


<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">DataConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;The data group configuration.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        train: An optional dictionary of data loader configurations. This configuration is directly</span>
<span class="sd">            mapped into dictionaries of data batches.</span>
<span class="sd">        val: An optional data loader configuration to use during validation.</span>
<span class="sd">        test: An optional data loader configuration to use for testing.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">train</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">DataLoaderConfig</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">val</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">DataLoaderConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">test</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">DataLoaderConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>


<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">LearnerConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;A base learner configuration.&quot;&quot;&quot;</span>

    <span class="n">_target_</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">MISSING</span>


<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">ClassifierConfig</span><span class="p">(</span><span class="n">LearnerConfig</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The classifier configuration.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        hparams: The classifier&#39;s hyperparameters.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">hparams</span><span class="p">:</span> <span class="n">ClassifierHParams</span> <span class="o">=</span> <span class="n">ClassifierHParams</span><span class="p">()</span>
    <span class="n">_target_</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sesemi.Classifier&quot;</span>
</pre></div>
</div>
<p>Each of the config attributes in turn have their own structure which may also be defined using a similar data structure.
All of these are specified in the <em>sesemi.config.structs</em> module.</p>
<p>These structured configurations can map directly to YAML and also enable type-checking when parsing user inputs.
Any of the nested attributes can be set both through config files as well as through the CLI.</p>
<p>As an example, to run the CLI and set the number of epochs to 100:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ open_sesemi run.num_epochs=100
</pre></div>
</div>
</div>
<div class="section" id="built-in-configurations">
<h2>Built-in Configurations<a class="headerlink" href="#built-in-configurations" title="Permalink to this headline">¶</a></h2>
<p>We have a couple built-in configurations which are packaged with the library. For instance, to use the imagewoof
configuration you can run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ open_sesemi -cn imagewoof
</pre></div>
</div>
<p>This assumes you have downloaded the imagewoof dataset to the <em>./data/imagewoof2</em> directory, but otherwise it should work out of the box.</p>
<p>There is also a configuration file named standard that can be used as a starting point for custom configs or to train
baseline models.</p>
</div>
<div class="section" id="datasets">
<h2>Datasets<a class="headerlink" href="#datasets" title="Permalink to this headline">¶</a></h2>
<p>Currently, the torchvision image folder dataset is the main one that is supported, however, datasets that follow a certain
format can be easily registered. The interface used to construct datasets is shown below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">dataset</span><span class="p">(</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">root</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">subset</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">image_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">IterableDataset</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;Builds a dataset.</span>

<span class="sd">    Args:</span>
<span class="sd">        name: The name of the dataset to build.</span>
<span class="sd">        root: The path to the image folder dataset.</span>
<span class="sd">        subset: The subset(s) to use.</span>
<span class="sd">        image_transform: The image transformations to apply.</span>
<span class="sd">        **kwargs: Any other arguments to forward to the underlying dataset builder.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The dataset.</span>
<span class="sd">    &quot;&quot;&quot;</span>
</pre></div>
</div>
<p>Note that the name used for image folder datasets is <em>image_folder</em>. Additionally, registering datasets is done using a
<em>register_dataset</em> decorator function, however, it’s possible to construct datasets without this.</p>
</div>
<div class="section" id="example">
<h2>Example<a class="headerlink" href="#example" title="Permalink to this headline">¶</a></h2>
<p>The following is a look at the standard configuration:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>defaults:
  - sesemi_config
run:
  accelerator: dp
  num_epochs: 50
  batch_size_per_gpu: 16
data:
  train:
    supervised:
      dataset:
        name: image_folder
        subset: train
        image_transform:
          _target_: sesemi.transforms.train_transforms
      shuffle: True
      pin_memory: True
      num_workers: 4
      drop_last: True
    rotation_prediction:
      dataset:
        name: image_folder
        image_transform:
          _target_: sesemi.transforms.train_transforms
      shuffle: True
      pin_memory: True
      num_workers: 4
      collate_fn:
        _target_: sesemi.collation.RotationTransformer
      drop_last: True
  val:
    dataset:
      name: image_folder
      subset: val
      image_transform:
        _target_: sesemi.transforms.center_crop_transforms
    shuffle: False
    pin_memory: True
    num_workers: 4
    drop_last: False
learner:
  hparams:
    num_classes: 10
    model:
      backbone:
        _target_: sesemi.PyTorchImageModels
        name: resnet50d
        freeze: False
        pretrained: False
        global_pool: avg
        drop_rate: 0.5
      supervised_loss:
        callable:
          _target_: torch.nn.CrossEntropyLoss
      regularization_loss_heads:
        rotation_prediction:
          head:
            _target_: sesemi.models.heads.loss.RotationPredictionLossHead
            input_data: rotation_prediction
            input_backbone: backbone
    optimizer:
      _target_: torch.optim.SGD
      lr: 0.1
      momentum: 0.9
      nesterov: True
      weight_decay: 0.0005
    lr_scheduler:
      scheduler:
        _target_: sesemi.PolynomialLR
        warmup_epochs: 10
        iters_per_epoch: ${sesemi:iterations_per_epoch}
        warmup_lr: 0.001
        lr_pow: 0.5
        max_iters: ${sesemi:max_iterations}
trainer:
  callbacks:
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      monitor: val/top1
      mode: max
      save_top_k: 1
      save_last: True
</pre></div>
</div>
<p>In it, you will find that there are sections defining data loaders for supervised and unsupervised (rotation prediction)
datasets. Additionally, their is a cross entropy loss function defined for the supervised branch as well as a
rotation prediction loss head defined as a regularization branch.</p>
<p>Also note how there are variable interpolations of the form ${sesemi:name}. These variables are filled in at runtime
and enable referencing specific kinds of information from the configuration that may not be known ahead of time. The
set of these variables that are available are defined by the <em>sesemi.config.resolvers.SESEMIConfigAttributes</em> object
which is shown below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SESEMIConfigAttributes</span><span class="p">(</span><span class="n">AttributeResolver</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The attributes exposed to SESEMI configuration files.</span>

<span class="sd">    These attributes can be referenced in the config files by following the omegaconf syntax for</span>
<span class="sd">    custom resolvers. For example, ${sesemi:iterations_per_epoch} will reference the</span>
<span class="sd">    `iterations_per_epoch` attribute.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        iterations_per_epoch: The number of training iterations per epoch if training data is</span>
<span class="sd">            available.</span>
<span class="sd">        max_iterations: The maximum number of training iterations if training data is available.</span>
<span class="sd">        num_gpus: The number of GPUs that will be used.</span>
<span class="sd">        num_nodes: The number of compute nodes that will be used.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">iterations_per_epoch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span>
    <span class="n">max_iterations</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span>
    <span class="n">num_gpus</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">num_nodes</span><span class="p">:</span> <span class="nb">int</span>
</pre></div>
</div>
<p>Going back to the first section of the config, there is a <em>defaults</em> section which is used to essentially import
configurations from other sources. In this case, the <em>sesemi_config</em> default specifies that the <em>SESEMIBaseConfig</em>
structure config along with some other overrides should be used. Additionally, a classifier learner is
set to be used.</p>
</div>
<div class="section" id="usage">
<h2>Usage<a class="headerlink" href="#usage" title="Permalink to this headline">¶</a></h2>
<p>There are two main ways you can use this package. For advanced users that aim to make code changes to the core library
it’s possible to clone the repository locally and pip install an editable version that will track your
modifications. If don’t need to make changes to the underlying codebase, you can instead use the open_sesemi
CLI which is installed with the pip package in order to run experiments. An example of how this can be done is shown below.</p>
<p>First create the following directory structure somewhere and enter /sesemi-experiments:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">/</span><span class="n">sesemi</span><span class="o">-</span><span class="n">experiments</span>         <span class="c1"># Stores your code, configurations, data, metrics, and models.</span>
  <span class="o">/</span><span class="n">configs</span>                  <span class="c1"># Your custom Hydra configurations.</span>
  <span class="o">/</span><span class="n">data</span>                     <span class="c1"># Any datasets you want to use.</span>
  <span class="o">/</span><span class="n">runs</span>                     <span class="c1"># Stores models and metrics generated by sesemi.</span>
  <span class="o">/</span><span class="n">src</span>                      <span class="c1"># Custom code with modules that you can instantiate from the configs.</span>
</pre></div>
</div>
<p>For this example, we’ll make use of the imagewoof dataset which can be downloaded using:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">curl</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">s3</span><span class="o">.</span><span class="n">amazonaws</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">fast</span><span class="o">-</span><span class="n">ai</span><span class="o">-</span><span class="n">imageclas</span><span class="o">/</span><span class="n">imagewoof2</span><span class="o">.</span><span class="n">tgz</span> <span class="o">|</span> <span class="n">tar</span> <span class="o">-</span><span class="n">xzv</span> <span class="o">-</span><span class="n">C</span> <span class="o">./</span><span class="n">data</span>
</pre></div>
</div>
<p>Next, create a custom config file with the following sample contents and store it under ./configs/custom.yaml:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">defaults</span><span class="p">:</span>
<span class="o">-</span> <span class="n">standard</span>
<span class="n">run</span><span class="p">:</span>
  <span class="n">seed</span><span class="p">:</span> <span class="mi">42</span>
  <span class="n">gpus</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span>
  <span class="n">num_epochs</span><span class="p">:</span> <span class="mi">80</span>
  <span class="nb">id</span><span class="p">:</span> <span class="n">imagewoof</span>
  <span class="n">data_root</span><span class="p">:</span> <span class="o">./</span><span class="n">data</span><span class="o">/</span><span class="n">imagewoof2</span>
</pre></div>
</div>
<p>This will use the built-in standard configuration and adds a couple of overrides. For a bare bones default
you can instead use sesemi_config. This example is the same as the provided imagewoof config.</p>
<p>You can inspect your custom config file using:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">open_sesemi</span> <span class="o">-</span><span class="n">cd</span> <span class="n">configs</span> <span class="o">-</span><span class="n">cn</span> <span class="n">custom</span> <span class="o">--</span><span class="n">info</span>
</pre></div>
</div>
<p>And finally, you can run your custom config file using:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">open_sesemi</span> <span class="o">-</span><span class="n">cd</span> <span class="n">configs</span> <span class="o">-</span><span class="n">cn</span> <span class="n">custom</span>
</pre></div>
</div>
<p>Note that -cd adds the directory configs to the config search path and -cn specifies that the custom config
should be loaded.</p>
<p>The same structure follows if you are using a locally clone repository. You will just be able to make modifications
to the core library as well.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="hydra.html" class="btn btn-neutral float-right" title="A Primer on Hydra" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="index.html" class="btn btn-neutral float-left" title="Image Classification with Self-Supervised Regularization" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Flyreel AI.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>