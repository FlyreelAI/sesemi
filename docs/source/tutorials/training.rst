Training Baseline Models
------------------------

Here we will describe the standard workflow involved with training a baseline model using
one of the provided methods. We primarily support the image folder dataset format though
allow for custom datasets that conform to our API. In this tutorial we will be assuming
that your data is in the image folder dataset format.

As described in the `Setting Up a Standard Project` page, we will be using the following
structure to organize our project::

    /experiments     # Stores your code, configurations, data, metrics, and models.
    /data            # Any datasets you want to use. Symlink data directories as necessary.
    /runs            # Stores models and metrics generated by SESEMI.
    /configs         # Your custom Hydra configurations.
    /src             # Custom code with packages that you can instantiate from the configs.
        /package_a     #   If you don't use a setup.py file to install these packages
        /package_b     #   you can instead configure your PYTHONPATH to point here as well.
    setup.py         # An optional setup file to install the packages in editable mode.

In the following section, we'll describe the steps involved with training a baseline model
using a semi-supervised method.

1. First, add (or symlink) your dataset to the `/data` directory using the name `baseline`. We will assume
   that the training set is under `train`, the validation set under `val`, and the unlabeled data under `unsup`.
2. Create a configuration file for your model under `/configs` using the name `baseline.yaml`.
   Inside we'll define a simple configuration that makes use of the consistency regularization
   method. You'll need to update the number of classes present in your dataset below and possibly
   adjust the training and evaluation resolution of your dataset images.

.. code-block:: yaml
    
    # @package _global_
    defaults:
    - /base/supervised/model                                # Base configuration.
    - /base/supervised/backbone/timm                        # Timm backbone defaults.
    - /base/supervised/head/linear                          # Linear classification head.
    - /base/supervised/optimizer/sgd                        # SGD optimizer defaults.
    - /base/supervised/lr_scheduler/cosine                  # Cosine lr scheduling defaults.
    - /base/consistency_minimization/model                  # Consistency minimization with EMA.
    run:
        seed: 42
        devices: 1                                          # Update as necessary.
        batch_size_per_device: 16
        num_epochs: 20                                      # Start with 20 epochs.
        id: baseline
        data_root: ./data/baseline
    learner:
        hparams:
            num_classes: ${NUM_CLASSES}                     # UPDATE
            model:
                backbone:
                    name: convnext_base_in22ft1k
                    pretrained: true
            optimizer:
                lr: 0.001
    data:
        train:
            supervised:
                dataset:
                    name: image_folder
                    subset: train
                    image_transform:
                        _target_: sesemi.transforms.TrainTransform
                        random_resized_crop: True
                        resize: 256                         # Image resolution.
                        crop_dim: 224                       # Image resolution.
                        scale: [0.3, 1.0]
                shuffle: True
                pin_memory: True
                num_workers: 4
                drop_last: True
            unsupervised:
                dataset:
                    name: ${data.train.supervised.dataset.name}
                    subset: [train, unsup]
                    image_transform:
                        _target_: sesemi.transforms.TwoViewsTransform
                        transform: ${data.train.supervised.dataset.image_transform}
                shuffle: True
                pin_memory: True
                num_workers: 4
                drop_last: True
        val:
            dataset:
                name: image_folder
                subset: val
                image_transform:
                    _target_: sesemi.transforms.CenterCropTransform
                    resize: 256                             # Image resolution.
                    crop_dim: 224                           # Image resolution.
            shuffle: False
            pin_memory: True
            num_workers: 4
            drop_last: False

3. Run training using this custom configuration as follows:

.. code-block:: bash

    $ open_sesemi -cd configs -cn baseline

4. Monitor training progress using the terminal or tensorboard using:

.. code-block:: bash

    $ tensorboard ./runs/baseline

5. Tune hyperparameters by sweeping over them, for example:

.. code-block:: bash

    $ open_sesemi -m -cd configs -cn baseline \
        run.batch_size_per_gpu=4,16,64 \
        learner.hparams.optimizer.lr=0.00001,0.0001,0.001,0.01