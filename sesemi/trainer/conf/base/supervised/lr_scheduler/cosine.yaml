# @package _global_
learner:
  hparams:
    lr_scheduler:
      scheduler:
        _target_: torch.optim.lr_scheduler.CosineAnnealingLR
        T_max: ${sesemi:max_iterations}